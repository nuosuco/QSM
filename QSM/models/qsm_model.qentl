#!/usr/bin/env qentl
# -*- coding: utf-8 -*-

"""
QSM - 量子自组织映射模型
基于量子编码和自组织映射的社交网络分析增强模型
"""

# 量子基因编码
QG-MODEL-QSM-SOCIAL-X7Y9

# 量子纠缠信道
@quantum_entangle
  channel_id: QE-MODEL-QSM-20240501
  state: ACTIVE
  strength: 0.98
  objects: [
    "QSM/api/qsm_api.qentl",
    "QSM/utils/qsm_utils.qentl",
    "QSM/services/qsm_service.qentl"
  ]

@imports
  standard: [os, json, logging, time, datetime, random, uuid, math]
  quantum: [Dict, List, Tuple, Any, Optional, Union, Path]
  quantum_collections: [defaultdict]
  quantum_numeric: [numpy as np]
  quantum_viz: [visualization]
  quantum_circuit: [
    QuantumCircuit,
    QuantumRegister,
    ClassicalRegister,
    Statevector
  ]

@constants
  ROOT_DIR = Path(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
  LOG_DIR = ROOT_DIR / 'logs'
  MODEL_DIR = ROOT_DIR / 'data' / 'models'
  
  # 关系类型常量
  RELATION_TYPES = {
    'FRIEND': 1,      # 朋友
    'FAMILY': 2,      # 家人
    'COLLEAGUE': 3,   # 同事
    'ACQUAINTANCE': 4, # 熟人
    'ROMANTIC': 5     # 恋人
  }
  
  # 消息类型常量
  MESSAGE_TYPES = {
    'TEXT': 1,        # 文本
    'IMAGE': 2,       # 图片
    'AUDIO': 3,       # 音频
    'VIDEO': 4,       # 视频
    'LINK': 5,        # 链接
    'QUANTUM': 6      # 量子消息
  }
  
  # 情绪类型常量
  EMOTION_TYPES = {
    'HAPPY': 1,       # 高兴
    'SAD': 2,         # 悲伤
    'ANGRY': 3,       # 愤怒
    'SURPRISED': 4,   # 惊讶
    'NEUTRAL': 5,     # 中性
    'ANXIOUS': 6,     # 焦虑
    'EXCITED': 7      # 兴奋
  }

@initialization
  # 创建日志和模型目录
  LOG_DIR.mkdir(exist_ok=True)
  MODEL_DIR.mkdir(exist_ok=True, parents=True)
  
  # 配置日志
  logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - [%(levelname)s] - %(message)s',
    handlers=[
      logging.FileHandler(LOG_DIR / f'qsm_model_{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
      logging.StreamHandler()
    ]
  )
  logger = logging.getLogger('QSMModel')

@class QuantumNode
  @constructor(node_id: str, dimension: int = 8)
    """初始化量子节点
    
    Args:
        node_id: 节点的唯一标识符
        dimension: 量子权重向量的维度
    """
    self.id = node_id
    self.dimension = dimension
    self.weights = np.random.uniform(0, 1, dimension)
    self.connections = {}  # 连接到其他节点的权重
    self.data = {}  # 存储节点相关的额外数据
    self.quantum_signature = f"QN-{uuid.uuid4().hex[:8]}"
    
    # 创建并初始化量子态
    self._initialize_quantum_state()
    
  @method _initialize_quantum_state()
    """初始化节点的量子态"""
    qreg = QuantumRegister(self.dimension, 'q')
    creg = ClassicalRegister(self.dimension, 'c')
    self.circuit = QuantumCircuit(qreg, creg)
    
    # 用权重值初始化量子态
    for i in range(self.dimension):
      theta = np.pi * self.weights[i]
      self.circuit.ry(theta, qreg[i])
      
    # 添加纠缠以增强节点内部特征关联
    for i in range(self.dimension-1):
      self.circuit.cx(qreg[i], qreg[i+1])
  
  @method update_weights(input_vector: np.ndarray, learning_rate: float)
    """更新节点的权重向量
    
    Args:
        input_vector: 输入向量
        learning_rate: 学习率
    """
    self.weights += learning_rate * (input_vector - self.weights)
    self._initialize_quantum_state()  # 重新初始化量子态以反映新权重
  
  @method measure_similarity(input_vector: np.ndarray) -> float
    """测量节点与输入向量的相似度
    
    Args:
        input_vector: 输入向量
        
    Returns:
        相似度分数
    """
    # 量子方式测量相似度 - 返回欧氏距离
    return np.linalg.norm(self.weights - input_vector)
  
  @method add_connection(node_id: str, weight: float = 1.0)
    """添加到另一个节点的连接
    
    Args:
        node_id: 目标节点ID
        weight: 连接权重
    """
    self.connections[node_id] = weight
    
  @method to_dict() -> Dict[str, Any]
    """将节点转换为字典表示
    
    Returns:
        节点的字典表示
    """
    return {
      'id': self.id,
      'weights': self.weights.tolist(),
      'connections': self.connections,
      'data': self.data,
      'quantum_signature': self.quantum_signature
    }
  
  @classmethod
  @method from_dict(data: Dict[str, Any]) -> 'QuantumNode'
    """从字典创建节点
    
    Args:
        data: 节点的字典表示
        
    Returns:
        创建的量子节点实例
    """
    node = cls(data['id'], len(data['weights']))
    node.weights = np.array(data['weights'])
    node.connections = data['connections']
    node.data = data['data']
    node.quantum_signature = data.get('quantum_signature', f"QN-{uuid.uuid4().hex[:8]}")
    node._initialize_quantum_state()
    return node

@class QSMModel
  @constructor(grid_size: Tuple[int, int] = (10, 10), input_dim: int = 8)
    """初始化QSM模型
    
    Args:
        grid_size: SOM网格大小 (宽, 高)
        input_dim: 输入特征维度
    """
    self.grid_size = grid_size
    self.input_dim = input_dim
    self.nodes = {}
    self.learning_rate = 0.1
    self.radius = max(grid_size) / 2
    self.time_constant = 1000 / np.log(self.radius)
    self.creation_time = datetime.datetime.now().isoformat()
    self.version = "1.0.0"
    self.quantum_gene = "QG-MODEL-QSM-SOCIAL-X7Y9"
    
    logger.info(f"初始化QSM模型: 网格大小={grid_size}, 输入维度={input_dim}")
    # 初始化SOM网格
    self._initialize_grid()
    
  @method _initialize_grid()
    """初始化SOM网格节点"""
    width, height = self.grid_size
    for x in range(width):
      for y in range(height):
        node_id = f"node_{x}_{y}"
        self.nodes[node_id] = QuantumNode(node_id, self.input_dim)
        self.nodes[node_id].data['position'] = (x, y)
  
  @method _find_bmu(input_vector: np.ndarray) -> str
    """找到最佳匹配单元(Best Matching Unit)
    
    Args:
        input_vector: 输入向量
        
    Returns:
        最佳匹配单元的ID
    """
    min_dist = float('inf')
    bmu_id = None
    
    for node_id, node in self.nodes.items():
      dist = node.measure_similarity(input_vector)
      if dist < min_dist:
        min_dist = dist
        bmu_id = node_id
        
    return bmu_id
  
  @method _calculate_influence(node_pos: Tuple[int, int], bmu_pos: Tuple[int, int], iteration: int) -> float
    """计算节点受BMU的影响程度
    
    Args:
        node_pos: 节点位置
        bmu_pos: BMU位置
        iteration: 当前迭代次数
        
    Returns:
        影响值
    """
    # 计算距离
    dist = np.linalg.norm(np.array(node_pos) - np.array(bmu_pos))
    
    # 计算当前迭代的半径
    radius = self.radius * np.exp(-iteration / self.time_constant)
    
    # 计算影响值
    if dist <= radius:
      return np.exp(-(dist**2) / (2 * (radius**2)))
    else:
      return 0
      
  @method train(data: List[np.ndarray], iterations: int = 1000)
    """训练QSM模型
    
    Args:
        data: 训练数据列表
        iterations: 训练迭代次数
    """
    logger.info(f"开始训练QSM模型: 数据量={len(data)}, 迭代次数={iterations}")
    
    initial_learning_rate = self.learning_rate
    
    for i in range(iterations):
      # 更新学习率
      self.learning_rate = initial_learning_rate * np.exp(-i / iterations)
      
      # 随机选择一个输入向量
      input_vector = data[np.random.randint(0, len(data))]
      
      # 找到最佳匹配单元
      bmu_id = self._find_bmu(input_vector)
      bmu_pos = self.nodes[bmu_id].data['position']
      
      # 更新所有节点
      for node_id, node in self.nodes.items():
        node_pos = node.data['position']
        influence = self._calculate_influence(node_pos, bmu_pos, i)
        
        if influence > 0:
          # 应用影响系数更新权重
          node.update_weights(input_vector, self.learning_rate * influence)
      
      if i % 100 == 0:
        logger.info(f"训练进度: {i}/{iterations}, 学习率: {self.learning_rate:.4f}")
  
  @method map_input(input_vector: np.ndarray) -> Tuple[str, Dict[str, float]]
    """将输入映射到QSM空间
    
    Args:
        input_vector: 输入向量
        
    Returns:
        (最佳匹配单元ID, 与所有节点的相似度字典)
    """
    similarities = {}
    for node_id, node in self.nodes.items():
      similarities[node_id] = 1.0 / (1.0 + node.measure_similarity(input_vector))
      
    # 找到最佳匹配单元
    bmu_id = max(similarities, key=similarities.get)
    
    return bmu_id, similarities
  
  @method cluster_data(data: List[np.ndarray]) -> Dict[str, List[int]]
    """将数据聚类
    
    Args:
        data: 要聚类的数据
        
    Returns:
        聚类结果，格式为 {node_id: [data_indices]}
    """
    clusters = defaultdict(list)
    
    for i, vector in enumerate(data):
      bmu_id, _ = self.map_input(vector)
      clusters[bmu_id].append(i)
      
    return dict(clusters)
  
  @method analyze_relationships(user_features: Dict[str, np.ndarray]) -> Dict[str, Dict[str, float]]
    """分析用户关系
    
    Args:
        user_features: 用户特征字典 {user_id: feature_vector}
        
    Returns:
        用户关系强度矩阵 {user1: {user2: strength}}
    """
    relationships = defaultdict(dict)
    
    # 将每个用户映射到网格
    user_mappings = {}
    for user_id, features in user_features.items():
      bmu_id, similarities = self.map_input(features)
      user_mappings[user_id] = (bmu_id, similarities)
    
    # 计算用户之间的关系强度
    for user1, (bmu1, sim1) in user_mappings.items():
      for user2, (bmu2, sim2) in user_mappings.items():
        if user1 != user2:
          # 计算两个BMU之间的相似度
          pos1 = self.nodes[bmu1].data['position']
          pos2 = self.nodes[bmu2].data['position']
          distance = np.linalg.norm(np.array(pos1) - np.array(pos2))
          
          # 关系强度基于相似度和距离
          strength = np.exp(-distance / 10.0)  # 标准化距离
          relationships[user1][user2] = strength
    
    return dict(relationships)
  
  @method recommend_connections(
                          user_id: str, 
                          user_features: Dict[str, np.ndarray], 
                          existing_connections: Dict[str, List[str]],
                          top_n: int = 5) -> List[Tuple[str, float]]
    """为用户推荐新连接
    
    Args:
        user_id: 用户ID
        user_features: 所有用户的特征向量
        existing_connections: 现有连接 {user_id: [connected_user_ids]}
        top_n: 返回的推荐数量
        
    Returns:
        推荐的连接列表 [(user_id, score)]
    """
    if user_id not in user_features:
      return []
      
    # 获取用户的现有连接
    user_connections = existing_connections.get(user_id, [])
    
    # 计算关系强度
    relationships = self.analyze_relationships(user_features)
    
    # 过滤掉已存在的连接
    recommendations = []
    for other_user, strength in relationships.get(user_id, {}).items():
      if other_user not in user_connections and other_user != user_id:
        recommendations.append((other_user, strength))
    
    # 按关系强度排序并返回前N个
    recommendations.sort(key=lambda x: x[1], reverse=True)
    return recommendations[:top_n]
  
  @method visualize_network(
                       user_features: Dict[str, np.ndarray], 
                       connections: Dict[str, List[str]]) -> Dict[str, Any]
    """生成网络可视化数据
    
    Args:
        user_features: 用户特征
        connections: 用户连接
        
    Returns:
        可视化数据
    """
    visualization = {
      'nodes': [],
      'links': [],
      'metadata': {
        'generated_at': datetime.datetime.now().isoformat(),
        'model_version': self.version,
        'quantum_gene': self.quantum_gene
      }
    }
    
    # 创建节点
    for user_id, features in user_features.items():
      bmu_id, _ = self.map_input(features)
      position = self.nodes[bmu_id].data['position']
      
      visualization['nodes'].append({
        'id': user_id,
        'group': hash(bmu_id) % 10,  # 简单的分组方法
        'x': position[0],
        'y': position[1],
        'node_type': 'user'
      })
    
    # 创建连接
    for source, targets in connections.items():
      for target in targets:
        if source in user_features and target in user_features:
          visualization['links'].append({
            'source': source,
            'target': target,
            'value': 1,
            'link_type': 'social'
          })
    
    return visualization
  
  @method save(filepath: Optional[str] = None) -> str
    """保存模型到文件
    
    Args:
        filepath: 保存路径，如果为None则自动生成
        
    Returns:
        保存的文件路径
    """
    if filepath is None:
      timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
      filepath = os.path.join(MODEL_DIR, f'qsm_model_{timestamp}.qsm')
      
    # 准备保存数据
    model_data = {
      'grid_size': self.grid_size,
      'input_dim': self.input_dim,
      'learning_rate': self.learning_rate,
      'radius': self.radius,
      'time_constant': self.time_constant,
      'creation_time': self.creation_time,
      'version': self.version,
      'quantum_gene': self.quantum_gene,
      'nodes': {node_id: node.to_dict() for node_id, node in self.nodes.items()}
    }
    
    # 确保目录存在
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    
    with open(filepath, 'w', encoding='utf-8') as f:
      json.dump(model_data, f, ensure_ascii=False, indent=2)
      
    logger.info(f"模型保存到: {filepath}")
    return filepath
  
  @classmethod
  @method load(filepath: str) -> 'QSMModel'
    """从文件加载模型
    
    Args:
        filepath: 模型文件路径
        
    Returns:
        加载的QSM模型
    """
    logger.info(f"从{filepath}加载模型")
    
    with open(filepath, 'r', encoding='utf-8') as f:
      model_data = json.load(f)
    
    # 创建模型实例
    model = cls(
      grid_size=tuple(model_data['grid_size']),
      input_dim=model_data['input_dim']
    )
    
    # 更新模型属性
    model.learning_rate = model_data['learning_rate']
    model.radius = model_data['radius']
    model.time_constant = model_data['time_constant']
    model.creation_time = model_data.get('creation_time', datetime.datetime.now().isoformat())
    model.version = model_data.get('version', "1.0.0")
    model.quantum_gene = model_data.get('quantum_gene', "QG-MODEL-QSM-SOCIAL-X7Y9")
    
    # 重建节点
    model.nodes = {}
    for node_id, node_data in model_data['nodes'].items():
      model.nodes[node_id] = QuantumNode.from_dict(node_data)
      
    return model
    
  @method to_dict() -> Dict[str, Any]
    """转换模型为字典表示
    
    Returns:
        模型的字典表示
    """
    return {
      'grid_size': self.grid_size,
      'input_dim': self.input_dim,
      'learning_rate': self.learning_rate,
      'radius': self.radius,
      'time_constant': self.time_constant,
      'nodes_count': len(self.nodes),
      'creation_time': self.creation_time,
      'version': self.version,
      'quantum_gene': self.quantum_gene
    }

@function create_qsm_model(grid_size: Tuple[int, int] = (10, 10), input_dim: int = 8) -> QSMModel:
  """创建一个QSM模型实例
  
  Args:
      grid_size: SOM网格大小 (宽, 高)
      input_dim: 输入特征维度
      
  Returns:
      QSM模型实例
  """
  return QSMModel(grid_size, input_dim)

@function get_relation_types() -> Dict[str, int]:
  """获取关系类型常量
  
  Returns:
      关系类型字典
  """
  return RELATION_TYPES

@function get_message_types() -> Dict[str, int]:
  """获取消息类型常量
  
  Returns:
      消息类型字典
  """
  return MESSAGE_TYPES

@function get_emotion_types() -> Dict[str, int]:
  """获取情绪类型常量
  
  Returns:
      情绪类型字典
  """
  return EMOTION_TYPES

@entrypoint
  # 示例代码
  if __name__ == "__main__":
    # 创建模型
    model = create_qsm_model(grid_size=(10, 10), input_dim=8)
    
    # 生成一些随机数据
    data = [np.random.random(8) for _ in range(100)]
    
    # 训练模型
    model.train(data, iterations=100)
    
    # 测试映射功能
    test_vector = np.random.random(8)
    bmu_id, similarities = model.map_input(test_vector)
    
    print(f"最佳匹配单元: {bmu_id}")
    print(f"前3个最相似节点: {sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:3]}")
    
    # 创建一些用户数据
    user_features = {
      f"user_{i}": np.random.random(8) for i in range(10)
    }
    
    # 创建一些连接
    connections = {
      f"user_{i}": [f"user_{j}" for j in range(10) if i != j and random.random() > 0.7]
      for i in range(10)
    }
    
    # 可视化网络
    network = model.visualize_network(user_features, connections)
    
    # 保存模型
    model.save() 