#!/usr/bin/env qentl
# -*- coding: utf-8 -*-

"""
QSM服务模块
提供量子自组织映射社交模型的服务层
"""

# 量子基因编码
QG-SERVICE-QSM-SOCIAL-S2E5

# 量子纠缠信道
@quantum_entangle
  channel_id: QE-SERVICE-QSM-20240501
  state: ACTIVE
  strength: 0.96
  objects: [
    "QSM/models/qsm_model.qentl",
    "QSM/api/qsm_api.qentl",
    "QSM/utils/qsm_utils.qentl"
  ]

@imports
  standard: [os, json, logging, datetime, time, uuid, threading]
  quantum: [Dict, List, Tuple, Any, Optional, Union, Path]
  quantum_numeric: [numpy as np]
  quantum_internal: [
    "../models/qsm_model.qentl" as qsm_model,
    "../utils/qsm_utils.qentl" as qsm_utils
  ]

@constants
  ROOT_DIR = Path(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
  LOG_DIR = ROOT_DIR / 'logs'
  DATA_DIR = ROOT_DIR / 'data'
  CACHE_DIR = DATA_DIR / 'cache'
  
  # 服务配置常量
  SERVICE_CONFIG = {
    'cache_ttl': 3600,  # 缓存生存时间(秒)
    'max_cache_size': 100,  # 最大缓存条目数
    'auto_save_interval': 300,  # 自动保存间隔(秒)
    'max_concurrent_jobs': 5,  # 最大并发作业数
    'default_model_params': {
      'grid_size': (10, 10),
      'input_dim': 8
    }
  }

@initialization
  # 创建目录
  LOG_DIR.mkdir(exist_ok=True)
  DATA_DIR.mkdir(exist_ok=True, parents=True)
  CACHE_DIR.mkdir(exist_ok=True, parents=True)
  
  # 配置日志
  logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - [%(levelname)s] - %(message)s',
    handlers=[
      logging.FileHandler(LOG_DIR / f'qsm_service_{datetime.datetime.now().strftime("%Y%m%d")}.log'),
      logging.StreamHandler()
    ]
  )
  logger = logging.getLogger('QSM-SERVICE')
  
  # 初始化缓存和作业管理
  _cache = {}
  _cache_timestamps = {}
  _active_jobs = {}
  _model_registry = {}
  _lock = threading.RLock()

@class QSMService
  @constructor()
    """初始化QSM服务"""
    self.default_model = qsm_model.create_qsm_model(**SERVICE_CONFIG['default_model_params'])
    self._stopped = False
    self._auto_save_thread = None
    
    # 启动自动保存线程
    self._start_auto_save()
    
    logger.info("QSM服务已初始化")
  
  @method _start_auto_save()
    """启动自动保存线程"""
    if self._auto_save_thread is None:
      self._stopped = False
      self._auto_save_thread = threading.Thread(target=self._auto_save_worker, daemon=True)
      self._auto_save_thread.start()
      logger.info("自动保存线程已启动")
  
  @method _auto_save_worker()
    """自动保存工作线程"""
    while not self._stopped:
      try:
        # 等待指定时间
        time.sleep(SERVICE_CONFIG['auto_save_interval'])
        
        if self._stopped:
          break
          
        # 保存所有注册的模型
        with _lock:
          for model_id, model_info in _model_registry.items():
            if model_info.get('auto_save', True):
              model = model_info['model']
              save_dir = CACHE_DIR / 'models'
              save_dir.mkdir(exist_ok=True)
              filepath = save_dir / f"{model_id}_{int(time.time())}.qsm"
              
              try:
                model.save(filepath)
                logger.info(f"已自动保存模型 {model_id} 到 {filepath}")
              except Exception as e:
                logger.error(f"自动保存模型 {model_id} 失败: {str(e)}")
      
      except Exception as e:
        logger.error(f"自动保存线程出错: {str(e)}")
        time.sleep(10)  # 出错后暂停一段时间
  
  @method stop()
    """停止服务"""
    self._stopped = True
    if self._auto_save_thread:
      self._auto_save_thread.join(timeout=10)
    logger.info("QSM服务已停止")
  
  @method register_model(model: qsm_model.QSMModel, model_id: Optional[str] = None, auto_save: bool = True) -> str:
    """注册模型
    
    Args:
        model: QSM模型实例
        model_id: 模型ID，如果为None则自动生成
        auto_save: 是否自动保存
        
    Returns:
        模型ID
    """
    with _lock:
      if model_id is None:
        model_id = f"model_{uuid.uuid4().hex[:8]}"
      
      _model_registry[model_id] = {
        'model': model,
        'registered_at': datetime.datetime.now().isoformat(),
        'auto_save': auto_save
      }
      
      logger.info(f"已注册模型: {model_id}")
      return model_id
  
  @method get_model(model_id: str) -> Optional[qsm_model.QSMModel]:
    """获取注册的模型
    
    Args:
        model_id: 模型ID
        
    Returns:
        QSM模型实例
    """
    with _lock:
      model_info = _model_registry.get(model_id)
      if model_info:
        return model_info['model']
      return None
  
  @method list_models() -> List[Dict[str, Any]]:
    """列出所有注册的模型
    
    Returns:
        模型信息列表
    """
    with _lock:
      return [
        {
          'model_id': model_id,
          'registered_at': info['registered_at'],
          'auto_save': info['auto_save'],
          'model_info': info['model'].to_dict()
        }
        for model_id, info in _model_registry.items()
      ]
  
  @method train_model(
               model_id: Optional[str],
               data: List[np.ndarray],
               iterations: int = 1000,
               async_mode: bool = False) -> Dict[str, Any]:
    """训练模型
    
    Args:
        model_id: 模型ID，如果为None则使用默认模型
        data: 训练数据
        iterations: 训练迭代次数
        async_mode: 是否异步训练
        
    Returns:
        训练结果
    """
    # 获取模型
    model = self.default_model
    if model_id is not None:
      model = self.get_model(model_id)
      if model is None:
        raise ValueError(f"未找到模型: {model_id}")
    
    # 创建训练作业
    job_id = f"job_train_{uuid.uuid4().hex[:8]}"
    
    if async_mode:
      # 异步训练
      with _lock:
        _active_jobs[job_id] = {
          'status': 'pending',
          'type': 'train',
          'model_id': model_id or 'default',
          'created_at': datetime.datetime.now().isoformat(),
          'params': {
            'data_size': len(data),
            'iterations': iterations
          }
        }
      
      # 启动训练线程
      threading.Thread(
        target=self._train_worker,
        args=(job_id, model, data, iterations),
        daemon=True
      ).start()
      
      return {
        'job_id': job_id,
        'status': 'pending',
        'message': '训练作业已创建'
      }
    else:
      # 同步训练
      logger.info(f"开始同步训练模型: 数据量={len(data)}, 迭代次数={iterations}")
      model.train(data, iterations=iterations)
      
      return {
        'status': 'completed',
        'message': f'模型训练完成: {len(data)}个数据点, {iterations}次迭代',
        'model_info': model.to_dict()
      }
  
  @method _train_worker(job_id: str, model: qsm_model.QSMModel, data: List[np.ndarray], iterations: int):
    """训练工作线程
    
    Args:
        job_id: 作业ID
        model: 模型实例
        data: 训练数据
        iterations: 训练迭代次数
    """
    try:
      # 更新作业状态
      with _lock:
        _active_jobs[job_id]['status'] = 'running'
        _active_jobs[job_id]['started_at'] = datetime.datetime.now().isoformat()
      
      logger.info(f"开始训练作业 {job_id}: 数据量={len(data)}, 迭代次数={iterations}")
      
      # 执行训练
      model.train(data, iterations=iterations)
      
      # 更新作业状态为完成
      with _lock:
        _active_jobs[job_id]['status'] = 'completed'
        _active_jobs[job_id]['completed_at'] = datetime.datetime.now().isoformat()
        
      logger.info(f"训练作业 {job_id} 已完成")
      
    except Exception as e:
      # 更新作业状态为失败
      logger.error(f"训练作业 {job_id} 失败: {str(e)}")
      with _lock:
        _active_jobs[job_id]['status'] = 'failed'
        _active_jobs[job_id]['error'] = str(e)
        _active_jobs[job_id]['failed_at'] = datetime.datetime.now().isoformat()
  
  @method get_job_status(job_id: str) -> Dict[str, Any]:
    """获取作业状态
    
    Args:
        job_id: 作业ID
        
    Returns:
        作业状态信息
    """
    with _lock:
      job_info = _active_jobs.get(job_id)
      if job_info:
        return job_info
      
    return {'status': 'not_found', 'job_id': job_id}
  
  @method analyze_network(
                     user_features: Dict[str, np.ndarray],
                     connections: Dict[str, List[str]],
                     model_id: Optional[str] = None) -> Dict[str, Any]:
    """分析网络
    
    Args:
        user_features: 用户特征
        connections: 用户连接
        model_id: 模型ID，如果为None则使用默认模型
        
    Returns:
        分析结果
    """
    # 获取模型
    model = self.default_model
    if model_id is not None:
      model = self.get_model(model_id)
      if model is None:
        raise ValueError(f"未找到模型: {model_id}")
    
    # 验证输入数据
    valid, error_msg = qsm_utils.validate_user_features(user_features)
    if not valid:
      raise ValueError(f"无效的用户特征数据: {error_msg}")
    
    valid, error_msg = qsm_utils.validate_connections(connections, list(user_features.keys()))
    if not valid:
      raise ValueError(f"无效的连接数据: {error_msg}")
    
    # 分析关系
    relationships = model.analyze_relationships(user_features)
    
    # 查找社区
    communities = qsm_utils.find_communities(connections)
    
    # 计算网络指标
    metrics = qsm_utils.calculate_network_metrics(connections)
    
    # 返回分析结果
    return {
      'relationships': relationships,
      'communities': communities,
      'metrics': metrics,
      'timestamp': datetime.datetime.now().isoformat(),
      'quantum_signature': f"QS-ANALYSIS-{uuid.uuid4().hex[:8]}"
    }
  
  @method recommend_connections(
                          user_id: str,
                          user_features: Dict[str, np.ndarray],
                          existing_connections: Dict[str, List[str]],
                          model_id: Optional[str] = None,
                          top_n: int = 5) -> Dict[str, Any]:
    """推荐连接
    
    Args:
        user_id: 用户ID
        user_features: 用户特征
        existing_connections: 现有连接
        model_id: 模型ID，如果为None则使用默认模型
        top_n: 推荐数量
        
    Returns:
        推荐结果
    """
    # 获取模型
    model = self.default_model
    if model_id is not None:
      model = self.get_model(model_id)
      if model is None:
        raise ValueError(f"未找到模型: {model_id}")
    
    # 验证用户ID
    if user_id not in user_features:
      raise ValueError(f"用户ID不存在: {user_id}")
    
    # 获取推荐
    recommendations = model.recommend_connections(
      user_id,
      user_features,
      existing_connections,
      top_n
    )
    
    # 缓存结果
    cache_key = f"recommend_{user_id}_{hash(str(user_features))}"
    with _lock:
      _cache[cache_key] = {
        'recommendations': recommendations,
        'timestamp': datetime.datetime.now().isoformat()
      }
      _cache_timestamps[cache_key] = time.time()
      
      # 清理过期缓存
      self._clean_cache()
    
    # 返回推荐结果
    return {
      'user_id': user_id,
      'recommendations': [
        {"user_id": rec[0], "score": float(rec[1])} 
        for rec in recommendations
      ],
      'timestamp': datetime.datetime.now().isoformat(),
      'quantum_signature': f"QS-RECOMMEND-{uuid.uuid4().hex[:8]}"
    }
  
  @method _clean_cache():
    """清理过期缓存"""
    current_time = time.time()
    expired_keys = []
    
    # 找出过期的缓存项
    for key, timestamp in _cache_timestamps.items():
      if current_time - timestamp > SERVICE_CONFIG['cache_ttl']:
        expired_keys.append(key)
    
    # 删除过期缓存
    for key in expired_keys:
      if key in _cache:
        del _cache[key]
      if key in _cache_timestamps:
        del _cache_timestamps[key]
    
    # 如果缓存太大，删除最旧的缓存
    if len(_cache) > SERVICE_CONFIG['max_cache_size']:
      # 按时间戳排序
      sorted_keys = sorted(_cache_timestamps.items(), key=lambda x: x[1])
      # 删除最旧的缓存，直到缓存大小符合要求
      keys_to_remove = sorted_keys[:len(_cache) - SERVICE_CONFIG['max_cache_size']]
      
      for key, _ in keys_to_remove:
        if key in _cache:
          del _cache[key]
        if key in _cache_timestamps:
          del _cache_timestamps[key]

@function create_qsm_service() -> QSMService:
  """创建QSM服务实例
  
  Returns:
      QSM服务实例
  """
  return QSMService()

@function get_service_config() -> Dict[str, Any]:
  """获取服务配置
  
  Returns:
      服务配置
  """
  return SERVICE_CONFIG 