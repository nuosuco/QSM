# attention

## 模块说明
量子语义注意力机制 (Quantum Semantic Attention)
包含多头注意力和自注意力机制实现

## 功能概述

### 类

- `QuantumSemanticAttention`
- `QuantumSelfAttention`
- `QuantumCrossAttention`
- `QuantumMultiModalAttention`
- `QuantumHierarchicalAttention`

### 函数

- `__init__`
- `__init__`

## 依赖关系

## 使用示例

## 注意事项

*文档最后更新时间：2025-04-12 15:31:10*